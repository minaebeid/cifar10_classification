+*In[6]:*+
[source, ipython3]
----
# Main file
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.optimizers import Adam
from keras.callbacks import CSVLogger, ModelCheckpoint
from keras.models import load_model
from keras.models import Model
from keras.layers import Input, Conv1D, Dense, Flatten, Activation, BatchNormalization
import tensorflow as tf
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import pickle

from pathlib import Path

###================================================================================================
### We are using model in the model_0.py file. Change this to load other models.
def model(input_shape):
    input = Input(input_shape)
    X = Flatten()(input)
    X = Dense(units=64, activation='relu')(X)
    X = Dense(units=10, activation='softmax')(X)

    model = Model(inputs=input, outputs=X)
    return model

###================================================================================================
# Specify model name to save model as. eg., "model_0", "model_1", "model_2"
MODEL_NAME = 'model_0'

###================================================================================================
### Plotting function
def set_size(w,h, ax=None):
    """ w, h: width, height in inches """
    if not ax: ax=plt.gca()
    l = ax.figure.subplotpars.left
    r = ax.figure.subplotpars.right
    t = ax.figure.subplotpars.top
    b = ax.figure.subplotpars.bottom
    figw = float(w)/(r-l)
    figh = float(h)/(t-b)
    ax.figure.set_size_inches(figw, figh)

def plot_Acc_And_Loss2(history_dict, save=True):
    """
    Plots loss and accuracy of train and val data over epochs.
    :return:
    """
    fig, axs = plt.subplots(1, 2)
    axs[0].plot(history_dict['accuracy'])
    axs[0].plot(history_dict['val_accuracy'])
    axs[0].set_title('training vs validation accuracy')
    axs[0].set_ylabel('accuracy')
    axs[0].set_xlabel('epoch')
    axs[0].legend(['train', 'val'], loc='upper left')
    axs[0].grid(True)

    axs[1].plot(history_dict['loss'])
    axs[1].plot(history_dict['val_loss'])
    axs[1].set_title('training vs validation loss')
    axs[1].set_ylabel('loss')
    axs[1].set_xlabel('epoch')
    axs[1].legend(['train', 'val'], loc='upper left')
    axs[1].grid(True)
    set_size(8,4)
    if save: plt.savefig('model_logs/'+MODEL_NAME+'_logs/'+MODEL_NAME+"_loss.png")
    plt.show()


###================================================================================================
BATCH_SIZE = 32
EPOCHS = 50

### CIFAR10 dataset loading:
### Partition data - data is already partioned from unpacking here:
(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()
input_shape = (32,32,3) # get 1st sample's shape.

# Check shape of each partition. Each img is 32x32x3. 50000 in training set, 10000 in test set.
print("x_train shape = " + str(np.shape(x_train)))
print("y_train shape = " + str(np.shape(y_train)))
print("x_test shape = " + str(np.shape(x_test)))
print("y_test shape = " + str(np.shape(y_test)))


###================================================================================================
### Compile a model.
model = model(input_shape)
opt = Adam(learning_rate=.0001)
loss = tf.keras.losses.SparseCategoricalCrossentropy()
metrics=['accuracy']
model.compile(optimizer=opt, loss=loss, metrics=metrics)
model.summary()


###================================================================================================
### Train and Predict.
model_checkpoint = ModelCheckpoint(filepath='model/'+MODEL_NAME,
                                       verbose=1,
                                       monitor='val_loss',
                                       save_best_only=True)
Path('model_logs/'+MODEL_NAME+'_logs/').mkdir(parents=True)
csv_logger = CSVLogger(filename='model_logs/'+MODEL_NAME+'_logs/'+MODEL_NAME+'_log.csv', separator=',', append=True)
# t0 = len(x_train)//BATCH_SIZE
model_history = model.fit(x=x_train, y=y_train, epochs=EPOCHS, callbacks=[csv_logger, model_checkpoint], validation_data=(x_test, y_test))


###================================================================================================
"""Save model history and plot loss and acc"""
"""
Note!!! If these files already exist, will get an error. 
"""
with open('model/'+MODEL_NAME+'/trainHistoryDict', 'wb') as file_name:
    pickle.dump(model_history.history, file_name)       # Save history dict
plot_Acc_And_Loss2(model_history.history)        # Plot acc and loss over epochs
with open('model_logs/'+MODEL_NAME+'_logs/'+MODEL_NAME+'_summary', 'w') as fh:
    # Pass the file handle in as a lambda function to make it callable
    model.summary(print_fn=lambda x: fh.write(x + '\n'))


###================================================================================================
### Evaluate model.
print("\nEvaluating model...\n")
test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)

pred_outs = model.predict(x_test)

pred_labels = np.argmax(pred_outs,axis=1)


# t0model = load_model("model/model_0") # Load a saved model from "model/..." and evaluate.
# t0predict = t0model.evaluate(x_test,  y_test, verbose=2)
----


+*Out[6]:*+
----
x_train shape = (50000, 32, 32, 3)
y_train shape = (50000, 1)
x_test shape = (10000, 32, 32, 3)
y_test shape = (10000, 1)
Model: "functional_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 3072)              0         
_________________________________________________________________
dense_6 (Dense)              (None, 64)                196672    
_________________________________________________________________
dense_7 (Dense)              (None, 10)                650       
=================================================================
Total params: 197,322
Trainable params: 197,322
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
1526/1563 [============================>.] - ETA: 0s - loss: 4.8712 - accuracy: 0.1006
Epoch 00001: val_loss improved from inf to 2.31627, saving model to model\model_0
INFO:tensorflow:Assets written to: model\model_0\assets
1563/1563 [==============================] - 3s 2ms/step - loss: 4.8115 - accuracy: 0.1005 - val_loss: 2.3163 - val_accuracy: 0.1004
Epoch 2/50
1538/1563 [============================>.] - ETA: 0s - loss: 2.3066 - accuracy: 0.0981
Epoch 00002: val_loss improved from 2.31627 to 2.30863, saving model to model\model_0
INFO:tensorflow:Assets written to: model\model_0\assets
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3065 - accuracy: 0.0981 - val_loss: 2.3086 - val_accuracy: 0.1002
Epoch 3/50
1537/1563 [============================>.] - ETA: 0s - loss: 2.3033 - accuracy: 0.0972
Epoch 00003: val_loss improved from 2.30863 to 2.30700, saving model to model\model_0
INFO:tensorflow:Assets written to: model\model_0\assets
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3032 - accuracy: 0.0973 - val_loss: 2.3070 - val_accuracy: 0.1000
Epoch 4/50
1531/1563 [============================>.] - ETA: 0s - loss: 2.3034 - accuracy: 0.0959 ETA: 0s - l
Epoch 00004: val_loss improved from 2.30700 to 2.30561, saving model to model\model_0
INFO:tensorflow:Assets written to: model\model_0\assets
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3034 - accuracy: 0.0960 - val_loss: 2.3056 - val_accuracy: 0.1000
Epoch 5/50
1554/1563 [============================>.] - ETA: 0s - loss: 2.3031 - accuracy: 0.0974
Epoch 00005: val_loss did not improve from 2.30561
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3031 - accuracy: 0.0974 - val_loss: 2.3063 - val_accuracy: 0.1000
Epoch 6/50
1551/1563 [============================>.] - ETA: 0s - loss: 2.3026 - accuracy: 0.0971
Epoch 00006: val_loss improved from 2.30561 to 2.30533, saving model to model\model_0
INFO:tensorflow:Assets written to: model\model_0\assets
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0970 - val_loss: 2.3053 - val_accuracy: 0.1000
Epoch 7/50
1550/1563 [============================>.] - ETA: 0s - loss: 2.3023 - accuracy: 0.0986
Epoch 00007: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3023 - accuracy: 0.0983 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 8/50
1562/1563 [============================>.] - ETA: 0s - loss: 2.3029 - accuracy: 0.0971
Epoch 00008: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 9/50
1561/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0968
Epoch 00009: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0967 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 10/50
1527/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0974
Epoch 00010: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0972 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 11/50
1556/1563 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.0953
Epoch 00011: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3030 - accuracy: 0.0952 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 12/50
1536/1563 [============================>.] - ETA: 0s - loss: 2.3025 - accuracy: 0.0980
Epoch 00012: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3025 - accuracy: 0.0977 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 13/50
1542/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0980
Epoch 00013: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3024 - accuracy: 0.0977 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 14/50
1552/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0985
Epoch 00014: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0985 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 15/50
1556/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0995
Epoch 00015: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3024 - accuracy: 0.0994 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 16/50
1544/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0992
Epoch 00016: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0990 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 17/50
1558/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0969
Epoch 00017: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0969 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 18/50
1530/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0957
Epoch 00018: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0959 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 19/50
1535/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0967 ETA: 0s - loss: 2.3025 - ac
Epoch 00019: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0966 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 20/50
1532/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0976
Epoch 00020: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0973 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 21/50
1545/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0980
Epoch 00021: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0979 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 22/50
1548/1563 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.0993
Epoch 00022: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3030 - accuracy: 0.0991 - val_loss: 2.3054 - val_accuracy: 0.0998
Epoch 23/50
1556/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0946
Epoch 00023: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3024 - accuracy: 0.0945 - val_loss: 2.3054 - val_accuracy: 0.0998
Epoch 24/50
1547/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0977
Epoch 00024: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0975 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 25/50
1545/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0976
Epoch 00025: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0975 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 26/50
1544/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0990
Epoch 00026: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0986 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 27/50
1547/1563 [============================>.] - ETA: 0s - loss: 2.3025 - accuracy: 0.0970
Epoch 00027: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0968 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 28/50
1526/1563 [============================>.] - ETA: 0s - loss: 2.3025 - accuracy: 0.0967
Epoch 00028: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0962 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 29/50
1538/1563 [============================>.] - ETA: 0s - loss: 2.3025 - accuracy: 0.0971
Epoch 00029: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0971 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 30/50
1531/1563 [============================>.] - ETA: 0s - loss: 2.3025 - accuracy: 0.0973
Epoch 00030: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0972 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 31/50
1559/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0952
Epoch 00031: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0952 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 32/50
1536/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0977
Epoch 00032: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0976 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 33/50
1550/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0984
Epoch 00033: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0982 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 34/50
1560/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0960
Epoch 00034: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0959 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 35/50
1559/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0980
Epoch 00035: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0981 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 36/50
1541/1563 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.0972
Epoch 00036: val_loss did not improve from 2.30533
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3030 - accuracy: 0.0971 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 37/50
1535/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0989
Epoch 00037: val_loss did not improve from 2.30533
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.0989 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 38/50
1562/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0978
Epoch 00038: val_loss did not improve from 2.30533
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.0978 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 39/50
1539/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0986
Epoch 00039: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3024 - accuracy: 0.0985 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 40/50
1533/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0965
Epoch 00040: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0967 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 41/50
1562/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0978
Epoch 00041: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3024 - accuracy: 0.0978 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 42/50
1523/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0975
Epoch 00042: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 2ms/step - loss: 2.3024 - accuracy: 0.0976 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 43/50
1542/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0979
Epoch 00043: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0977 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 44/50
1556/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0983
Epoch 00044: val_loss did not improve from 2.30533
1563/1563 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.0984 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 45/50
1555/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0979 ETA: 0s - loss: 2
Epoch 00045: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0978 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 46/50
1547/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0966
Epoch 00046: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0966 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 47/50
1561/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0956
Epoch 00047: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0956 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 48/50
1537/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0964
Epoch 00048: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0958 - val_loss: 2.3054 - val_accuracy: 0.0999
Epoch 49/50
1521/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0962
Epoch 00049: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0961 - val_loss: 2.3054 - val_accuracy: 0.1000
Epoch 50/50
1561/1563 [============================>.] - ETA: 0s - loss: 2.3024 - accuracy: 0.0973
Epoch 00050: val_loss did not improve from 2.30533
1563/1563 [==============================] - 2s 1ms/step - loss: 2.3024 - accuracy: 0.0973 - val_loss: 2.3054 - val_accuracy: 0.0999

![png](output_0_1.png)


Evaluating model...

313/313 - 0s - loss: 2.3054 - accuracy: 0.0999
----


+*In[ ]:*+
[source, ipython3]
----

----
